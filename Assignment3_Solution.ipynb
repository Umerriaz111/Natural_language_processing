{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246f9aec",
   "metadata": {},
   "source": [
    "## 1.1 - Getting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6bd0159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/umerriaz/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4a7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of fileids for training and testing sets\n",
    "\n",
    "train_docs=[d for d in reuters.fileids() if d.startswith(\"train\")]\n",
    "test_docs=[d for d in reuters.fileids() if d.startswith(\"test\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c39ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "training_data = [reuters.raw(doc_id) for doc_id in train_docs]\n",
    "training_labels = [reuters.categories(doc_id)[0] for doc_id in train_docs]\n",
    "\n",
    "testing_data = [reuters.raw(doc_id) for doc_id in test_docs]\n",
    "testing_labels = [reuters.categories(doc_id)[0] for doc_id in test_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa030c93",
   "metadata": {},
   "source": [
    "### Merging the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25828006",
   "metadata": {},
   "outputs": [],
   "source": [
    "Complete_training_data = training_data+testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a5e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Complete_training_labels = training_labels + testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d539b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10788"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Complete_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c8834e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10788"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Complete_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf4181c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAHIA COCOA REVIEW\\n  Showers continued throug...</td>\n",
       "      <td>cocoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMPUTER TERMINAL SYSTEMS &amp;lt;CPML&gt; COMPLETES ...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N.Z. TRADING BANK DEPOSIT GROWTH RISES SLIGHTL...</td>\n",
       "      <td>money-supply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NATIONAL AMUSEMENTS AGAIN UPS VIACOM &amp;lt;VIA&gt; ...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROGERS &amp;lt;ROG&gt; SEES 1ST QTR NET UP SIGNIFICAN...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>N.Z.'S CHASE CORP MAKES OFFER FOR ENTREGROWTH\\...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>TOKYO DEALERS SEE DOLLAR POISED TO BREACH 140 ...</td>\n",
       "      <td>dlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>JAPAN/INDIA CONFERENCE CUTS GULF WAR RISK CHAR...</td>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>SOVIET INDUSTRIAL GROWTH/TRADE SLOWER IN 1987\\...</td>\n",
       "      <td>ipi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>SIX KILLED IN SOUTH AFRICAN GOLD MINE ACCIDENT...</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text         Label\n",
       "0      BAHIA COCOA REVIEW\\n  Showers continued throug...         cocoa\n",
       "1      COMPUTER TERMINAL SYSTEMS &lt;CPML> COMPLETES ...           acq\n",
       "2      N.Z. TRADING BANK DEPOSIT GROWTH RISES SLIGHTL...  money-supply\n",
       "3      NATIONAL AMUSEMENTS AGAIN UPS VIACOM &lt;VIA> ...           acq\n",
       "4      ROGERS &lt;ROG> SEES 1ST QTR NET UP SIGNIFICAN...          earn\n",
       "...                                                  ...           ...\n",
       "10783  N.Z.'S CHASE CORP MAKES OFFER FOR ENTREGROWTH\\...           acq\n",
       "10784  TOKYO DEALERS SEE DOLLAR POISED TO BREACH 140 ...           dlr\n",
       "10785  JAPAN/INDIA CONFERENCE CUTS GULF WAR RISK CHAR...          ship\n",
       "10786  SOVIET INDUSTRIAL GROWTH/TRADE SLOWER IN 1987\\...           ipi\n",
       "10787  SIX KILLED IN SOUTH AFRICAN GOLD MINE ACCIDENT...          gold\n",
       "\n",
       "[10788 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(Complete_training_data,Complete_training_labels)), columns =['Text', 'Label']) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99abf4aa",
   "metadata": {},
   "source": [
    "## 1.2 Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d2d37be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/umerriaz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/umerriaz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Initialize stopwords, lemmatizer, and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Specify the column name containing the text data\n",
    "column_name = 'Text'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ec788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess each row of the specified column\n",
    "def preprocess_text(row):\n",
    "    # Tokenize the text into individual words\n",
    "    words = nltk.word_tokenize(row[column_name])\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Stem words\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join the preprocessed words back into a string\n",
    "    processed_text = ' '.join(words)\n",
    "    \n",
    "    # Update the row with the preprocessed text\n",
    "    row[column_name] = processed_text\n",
    "    \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c278b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to each row of the specified column\n",
    "df = df.apply(preprocess_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c20c7905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bahia cocoa review shower continu throughout w...</td>\n",
       "      <td>cocoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comput termin system &amp; lt ; cpml &gt; complet sal...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n.z . trade bank deposit growth rise slightli ...</td>\n",
       "      <td>money-supply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nation amus up viacom &amp; lt ; via &gt; bid viacom ...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roger &amp; lt ; rog &gt; see 1st qtr net significant...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>n.z . 's chase corp make offer entregrowth cha...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>tokyo dealer see dollar pois breach 140 yen to...</td>\n",
       "      <td>dlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>japan/india confer cut gulf war risk charg jap...</td>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>soviet industri growth/trad slower 1987 soviet...</td>\n",
       "      <td>ipi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>six kill south african gold mine accid six bla...</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text         Label\n",
       "0      bahia cocoa review shower continu throughout w...         cocoa\n",
       "1      comput termin system & lt ; cpml > complet sal...           acq\n",
       "2      n.z . trade bank deposit growth rise slightli ...  money-supply\n",
       "3      nation amus up viacom & lt ; via > bid viacom ...           acq\n",
       "4      roger & lt ; rog > see 1st qtr net significant...          earn\n",
       "...                                                  ...           ...\n",
       "10783  n.z . 's chase corp make offer entregrowth cha...           acq\n",
       "10784  tokyo dealer see dollar pois breach 140 yen to...           dlr\n",
       "10785  japan/india confer cut gulf war risk charg jap...          ship\n",
       "10786  soviet industri growth/trad slower 1987 soviet...           ipi\n",
       "10787  six kill south african gold mine accid six bla...          gold\n",
       "\n",
       "[10788 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4b8e6",
   "metadata": {},
   "source": [
    "## 1.3 Splitting the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae348634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df['Text'] \n",
    "y = df['Label']  \n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abe24f",
   "metadata": {},
   "source": [
    "## 2. Feature extraction\n",
    "\n",
    "### Using word embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bcf2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN,Dense,Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e23d6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c782cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3caeed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "max_sequence_length = max([len(seq) for seq in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e0eca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c2dc3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85340722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Word Embedding model\n",
    "embedding_dim = 10\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=padded_sequences.shape[1]),\n",
    "    tf.keras.layers.Flatten()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0b04a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = model.predict(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b730dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical format\n",
    "import numpy as np\n",
    "label_mapping = {label: i for i, label in enumerate(y.unique())}\n",
    "numeric_labels = ([label_mapping[label] for label in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f51d6220",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame({'Numeric_labels': numeric_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "550fe4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_data = pd.concat([pd.DataFrame(word_embeddings), dff], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d3dac9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22881</th>\n",
       "      <th>22882</th>\n",
       "      <th>22883</th>\n",
       "      <th>22884</th>\n",
       "      <th>22885</th>\n",
       "      <th>22886</th>\n",
       "      <th>22887</th>\n",
       "      <th>22888</th>\n",
       "      <th>22889</th>\n",
       "      <th>Numeric_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.030067</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049302</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.032746</td>\n",
       "      <td>0.030447</td>\n",
       "      <td>-0.016130</td>\n",
       "      <td>-0.020134</td>\n",
       "      <td>-0.022369</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.030067</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039339</td>\n",
       "      <td>-0.039835</td>\n",
       "      <td>0.046602</td>\n",
       "      <td>0.019698</td>\n",
       "      <td>0.037573</td>\n",
       "      <td>-0.037152</td>\n",
       "      <td>-0.033291</td>\n",
       "      <td>-0.034618</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.030067</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>-0.012508</td>\n",
       "      <td>-0.048204</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>-0.034915</td>\n",
       "      <td>0.043576</td>\n",
       "      <td>-0.019707</td>\n",
       "      <td>-0.030057</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.030067</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>-0.023971</td>\n",
       "      <td>-0.004670</td>\n",
       "      <td>0.036734</td>\n",
       "      <td>-0.021561</td>\n",
       "      <td>-0.017622</td>\n",
       "      <td>-0.023365</td>\n",
       "      <td>-0.028015</td>\n",
       "      <td>-0.004436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.030067</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028957</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>-0.037259</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.034617</td>\n",
       "      <td>0.039967</td>\n",
       "      <td>0.034210</td>\n",
       "      <td>0.043840</td>\n",
       "      <td>0.036190</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>-0.030067</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>-0.040034</td>\n",
       "      <td>-0.038340</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>-0.020824</td>\n",
       "      <td>-0.045036</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.039150</td>\n",
       "      <td>0.046967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>-0.030067</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026717</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.039936</td>\n",
       "      <td>-0.021248</td>\n",
       "      <td>-0.003175</td>\n",
       "      <td>0.028122</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.042086</td>\n",
       "      <td>0.028770</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>-0.030067</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045825</td>\n",
       "      <td>-0.046434</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.012565</td>\n",
       "      <td>-0.045121</td>\n",
       "      <td>0.030795</td>\n",
       "      <td>-0.020941</td>\n",
       "      <td>-0.014373</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>-0.030067</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011692</td>\n",
       "      <td>0.049926</td>\n",
       "      <td>0.037447</td>\n",
       "      <td>-0.024279</td>\n",
       "      <td>-0.034484</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.033883</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>-0.030067</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.036057</td>\n",
       "      <td>0.038567</td>\n",
       "      <td>-0.035065</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>0.046508</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>-0.023793</td>\n",
       "      <td>-0.034059</td>\n",
       "      <td>-0.016107</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>0.028803</td>\n",
       "      <td>-0.011888</td>\n",
       "      <td>-0.033009</td>\n",
       "      <td>0.038721</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows × 22891 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.030067 -0.021527 -0.036057  0.038567 -0.035065 -0.040354 -0.035469   \n",
       "1     -0.030067 -0.021527 -0.036057  0.038567 -0.035065 -0.040354 -0.035469   \n",
       "2     -0.030067 -0.021527 -0.036057  0.038567 -0.035065 -0.040354 -0.035469   \n",
       "3     -0.030067 -0.021527 -0.036057  0.038567 -0.035065 -0.040354 -0.035469   \n",
       "4     -0.030067 -0.021527 -0.036057  0.038567 -0.035065 -0.040354 -0.035469   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10783 -0.030067 -0.021527 -0.036057  0.038567 -0.035065 -0.040354 -0.035469   \n",
       "10784 -0.030067 -0.021527 -0.036057  0.038567 -0.035065 -0.040354 -0.035469   \n",
       "10785 -0.030067 -0.021527 -0.036057  0.038567 -0.035065 -0.040354 -0.035469   \n",
       "10786 -0.030067 -0.021527 -0.036057  0.038567 -0.035065 -0.040354 -0.035469   \n",
       "10787 -0.030067 -0.021527 -0.036057  0.038567 -0.035065 -0.040354 -0.035469   \n",
       "\n",
       "              7         8         9  ...     22881     22882     22883  \\\n",
       "0     -0.003351  0.046508 -0.005816  ...  0.049302  0.028924  0.032746   \n",
       "1     -0.003351  0.046508 -0.005816  ... -0.039339 -0.039835  0.046602   \n",
       "2     -0.003351  0.046508 -0.005816  ... -0.000351  0.004230 -0.012508   \n",
       "3     -0.003351  0.046508 -0.005816  ... -0.010336 -0.023971 -0.004670   \n",
       "4     -0.003351  0.046508 -0.005816  ... -0.028957  0.049113 -0.037259   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "10783 -0.003351  0.046508 -0.005816  ... -0.000532 -0.040034 -0.038340   \n",
       "10784 -0.003351  0.046508 -0.005816  ... -0.026717  0.022293  0.039936   \n",
       "10785 -0.003351  0.046508 -0.005816  ... -0.045825 -0.046434  0.003262   \n",
       "10786 -0.003351  0.046508 -0.005816  ... -0.011692  0.049926  0.037447   \n",
       "10787 -0.003351  0.046508 -0.005816  ...  0.019364 -0.023793 -0.034059   \n",
       "\n",
       "          22884     22885     22886     22887     22888     22889  \\\n",
       "0      0.030447 -0.016130 -0.020134 -0.022369 -0.006564  0.008197   \n",
       "1      0.019698  0.037573 -0.037152 -0.033291 -0.034618  0.006462   \n",
       "2     -0.048204  0.010063 -0.034915  0.043576 -0.019707 -0.030057   \n",
       "3      0.036734 -0.021561 -0.017622 -0.023365 -0.028015 -0.004436   \n",
       "4      0.004704  0.034617  0.039967  0.034210  0.043840  0.036190   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "10783  0.019956 -0.020824 -0.045036  0.003691  0.039150  0.046967   \n",
       "10784 -0.021248 -0.003175  0.028122  0.000609  0.042086  0.028770   \n",
       "10785  0.006246  0.012565 -0.045121  0.030795 -0.020941 -0.014373   \n",
       "10786 -0.024279 -0.034484  0.001343  0.033883  0.000656  0.004335   \n",
       "10787 -0.016107  0.010334  0.028803 -0.011888 -0.033009  0.038721   \n",
       "\n",
       "       Numeric_labels  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   2  \n",
       "3                   1  \n",
       "4                   3  \n",
       "...               ...  \n",
       "10783               1  \n",
       "10784              10  \n",
       "10785              28  \n",
       "10786              22  \n",
       "10787              20  \n",
       "\n",
       "[10788 rows x 22891 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a81bc5",
   "metadata": {},
   "source": [
    "## 3. Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32426944",
   "metadata": {},
   "source": [
    "## 3.1 Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00932d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Pad sequences to ensure equal length\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Convert labels to numerical format\n",
    "label_mapping = {label: i for i, label in enumerate(y.unique())}\n",
    "numeric_labels = np.array([label_mapping[label] for label in y])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, numeric_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the RNN model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 10\n",
    "hidden_units = 32\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length))\n",
    "model1.add(SimpleRNN(hidden_units))\n",
    "model1.add(Dense(len(label_mapping), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model1.fit(X_train, y_train, epochs=2, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f818e",
   "metadata": {},
   "source": [
    "## 3.2.  LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 10\n",
    "hidden_units = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(len(label_mapping), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fca967",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba9498",
   "metadata": {},
   "source": [
    "## 4.1 Comparing the performance\n",
    "\n",
    "###### As we can observe, the LSTM model achieves higher accuracy compared to the RNN model, which can be attributed to several reasons.\n",
    "\n",
    "1.LSTM models, as a specific type of Recurrent Neural Networks (RNNs), possess the capability to capture long-term   dependencies by incorporating an additional mechanism for retaining information over extended periods of time.\n",
    "\n",
    "2. LSTMs have a larger parameter space compared to basic RNNs due to their more complex architecture. This expanded   capacity enables LSTMs to capture intricate patterns in the data, potentially leading to higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294a404",
   "metadata": {},
   "source": [
    "## 4.2 Plotting the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the RNN model and store the history\n",
    "rnn_history = model1.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Train the LSTM model and store the history\n",
    "lstm_history = model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Plot the accuracy curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(rnn_history.history['accuracy'], label='RNN Training Accuracy')\n",
    "plt.plot(rnn_history.history['val_accuracy'], label='RNN Validation Accuracy')\n",
    "plt.plot(lstm_history.history['accuracy'], label='LSTM Training Accuracy')\n",
    "plt.plot(lstm_history.history['val_accuracy'], label='LSTM Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the loss curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(rnn_history.history['loss'], label='RNN Training Loss')\n",
    "plt.plot(rnn_history.history['val_loss'], label='RNN Validation Loss')\n",
    "plt.plot(lstm_history.history['loss'], label='LSTM Training Loss')\n",
    "plt.plot(lstm_history.history['val_loss'], label='LSTM Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86620853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
