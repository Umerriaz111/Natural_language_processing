{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47295230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c89a7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy cat \",\n",
    "    \"I like to eat pizza and hamburgers\",\n",
    "    \"The sun is shining and the birds are singing\",\n",
    "    \"She sells seashells by the seashore\",\n",
    "    \"He is a very talented musician and singer\",\n",
    "    \"The cat in the hat sat on a mat\",\n",
    "    \"It's raining cats and dogs outside\",\n",
    "    \"The United States of America is a large country.\",\n",
    "    \"I need to buy milk, bread, and eggs at the store.\",\n",
    "    \"My favorite color is blue, but I also like green.\",\n",
    "    \"The early bird catches the worm.\",\n",
    "    \"The world is full of wonder and mystery.\",\n",
    "    \"I have a dog named Max and a cat named Whiskers.\",\n",
    "    \"The sky is a beautiful shade of blue today.\",\n",
    "    \"She is a kind and caring person.\",\n",
    "    \"The moon is full tonight and the stars are bright.\",\n",
    "    \"I love to read books and watch movies.\",\n",
    "    \"The grass is always greener on the other side.\",\n",
    "    \"The ocean is vast and full of life.\",\n",
    "    \"He is an excellent cook and loves to experiment with flavors.\",\n",
    "    \"Life is a journey, not a destination.\",\n",
    "    \"I need to do laundry and clean the house today.\",\n",
    "    \"The mountains are majestic and awe-inspiring.\",\n",
    "    \"She has a passion for photography and takes beautiful pictures.\",\n",
    "    \"The apple doesn't fall far from the tree.\",\n",
    "    \"The rainforest is a complex ecosystem with many layers.\",\n",
    "    \"He is a hardworking and dedicated employee.\",\n",
    "    \"The night sky is a canvas of stars and constellations.\",\n",
    "    \"I enjoy hiking and being outdoors in nature.\",\n",
    "    \"The city never sleeps and is always bustling with activity.\",\n",
    "    \"She has a collection of antique dolls that are very valuable.\",\n",
    "    \"The desert is a harsh environment with extreme temperatures.\",\n",
    "    \"Life is too short to waste time on things that don't matter.\",\n",
    "    \"I need to call my mother and wish her a happy birthday.\",\n",
    "    \"The universe is vast and infinite.\",\n",
    "    \"She is a talented artist and creates beautiful paintings.\",\n",
    "    \"The river flows gently through the countryside.\",\n",
    "    \"He is a skilled carpenter and can build house for my cat.\",\n",
    "    \"The sun sets in the west and rises in the east.\",\n",
    "    \"My cat love to travel and explore new places.\",\n",
    "    \"The future is uncertain, but full of possibilities.\",\n",
    "    \"She is a brave and courageous woman.\",\n",
    "    \"The forest is home to many different animals and plants.\",\n",
    "    \"He is a wise and knowledgeable old man.\",\n",
    "    \"The beach is a great place to relax and soak up the sun.\",\n",
    "    \"Life is like a box of chocolates, you never know what you're going to get.\",\n",
    "    \"I need to go to the bank and deposit my paycheck.\",\n",
    "    \"The earth is a fragile ecosystem that must be protected.\",\n",
    "    \"She is a talented musician and plays the piano beautifully.\",\n",
    "    \"The wind blows gently through the trees.\",\n",
    "    \"He is a successful businessman and has a lot of experience.\",\n",
    "    \"The snow is falling softly outside and the world is quiet.\",\n",
    "    \"I enjoy cooking and experimenting with new recipes.\",\n",
    "    \"The sky is a beautiful canvas of colors during a sunset.\",\n",
    "    \"The world is changing rapidly and we must adapt.\",\n",
    "    \"She is a kind-hearted and compassionate person.\",\n",
    "    \"The jungle is full of danger and excitement.\",\n",
    "    \"He is a charismatic and persuasive speaker.\",\n",
    "    \"The sea is vast and full of mystery.\",\n",
    "    \"Life is full of surprises and unexpected twists.\",\n",
    "    \"I love pizza.\",\n",
    "    \"My favorite color is blue.\",\n",
    "    \"The cat jumped off the table.\",\n",
    "    \"I like to run in the park.\",\n",
    "    \"The dog chased the ball.\",\n",
    "    \"My sister is studying biology.\",\n",
    "    \"I enjoy playing video games.\",\n",
    "    \"The sun is shining brightly today.\",\n",
    "    \"My parents went on vacation.\",\n",
    "    \"I need to buy groceries.\",\n",
    "    \"I am learning how to cook.\",\n",
    "    \"My brother is playing basketball.\",\n",
    "    \"I have a headache.\",\n",
    "    \"The car needs an oil change.\",\n",
    "    \"I want to learn how to play the guitar.\",\n",
    "    \"The sky is turning red at sunset.\",\n",
    "    \"My friends and I went to the movies.\",\n",
    "    \"I am allergic to peanuts.\",\n",
    "    \"The book was very interesting.\",\n",
    "    \"I need to do my homework.\",\n",
    "    \"The train was delayed.\",\n",
    "    \"I went for a walk in the park.\",\n",
    "    \"My favorite animal is cat.\",\n",
    "    \"I am excited for the concert.\",\n",
    "    \"My cat is black color.\",\n",
    "    \"I watched a scary movie last night.\",\n",
    "    \"My cat love to swim.\",\n",
    "    \"I need to do laundry.\",\n",
    "    \"The snow is falling outside.\",\n",
    "    \"I love going to the beach.\",\n",
    "    \"My laptop is running slow.\",\n",
    "    \"I want another cat.\",\n",
    "    \"The sun is setting over the ocean.\",\n",
    "    \"I am feeling tired today.\",\n",
    "    \"The internet is not working\",\n",
    "    \"I want to learn how to dance\",\n",
    "    \"The flowers are blooming in the garden\",\n",
    "    \"My phone battery is low\",\n",
    "    \"I need to go grocery shopping\",\n",
    "    \"My phone is turnoff \"\n",
    "  \n",
    "     ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd2c6b",
   "metadata": {},
   "source": [
    "# Part 1: Finding related documents."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7fcc476",
   "metadata": {},
   "source": [
    "Assuming each sentence is a document \n",
    "I will use TF_IDF for finding related documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b139654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1591e2a0",
   "metadata": {},
   "source": [
    "# 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc16550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer=TfidfVectorizer()\n",
    "Model=Vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1e92ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vecabulary=Vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969641b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simiarity=Model.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73e07630",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_word=Vecabulary['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "257c75b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Words_score=Model[:,index_of_word].toarray().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddd52a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(-Words_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e378f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_arr = Words_score[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ec788b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Top10=sorted_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57eaa2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 related documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.44419135, 0.40740467, 0.4064562 , 0.4064562 , 0.33165165,\n",
       "       0.28937014, 0.2771658 , 0.2520293 , 0.24681035, 0.22747627])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 10 related documents\")\n",
    "Top10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584bd3d",
   "metadata": {},
   "source": [
    "# 1.2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "301e2f64",
   "metadata": {},
   "source": [
    "The TF_IDF method select only those files where occurance of words fould for example lets consider the word \"Cat\" so it will select only thouse document where cat word occurs with in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18ecc1",
   "metadata": {},
   "source": [
    "# Part :2 Minimum edit distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fbd5b1",
   "metadata": {},
   "source": [
    "# 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1619f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(str1, str2):\n",
    "    m = len(str1)\n",
    "    n = len(str2)\n",
    "    dp = [[0] * (n+1) for _ in range(m+1)]\n",
    "    \n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i\n",
    "            elif str1[i-1] == str2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i][j-1],    # Insert\n",
    "                                   dp[i-1][j],    # Remove\n",
    "                                   dp[i-1][j-1])  # Replace\n",
    "    \n",
    "    return dp[m][n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b714e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_edit_distance(\"umer\",'umar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c469c",
   "metadata": {},
   "source": [
    "# 2.2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e264a545",
   "metadata": {},
   "source": [
    "compute the similarity between two pairs of the 10 selected documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc325dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_edit_distance(documents[0],documents[92])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980e47c",
   "metadata": {},
   "source": [
    "# 2.3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "307170bc",
   "metadata": {},
   "source": [
    "Limitations of the minimum edit distance algorithm in measuring text similarity are following\n",
    "1)Sensitivity to word order\n",
    "2)Lack of semantic understanding\n",
    "3)Inability to handle long texts (computationally expensive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5edd8ff",
   "metadata": {},
   "source": [
    "# 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a57ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distance=nltk.edit_distance('umer',\"umar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7530a84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum rdit distance is 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum rdit distance is {}\".format(min_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352bd5e",
   "metadata": {},
   "source": [
    "# Part 3: Term Frequency and Inverse document frequency "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2644dee2",
   "metadata": {},
   "source": [
    "# 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d73ba526",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tokens=[]\n",
    "for sentences in documents:\n",
    "    words_tokens.append(word_tokenize(sentences))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855457d",
   "metadata": {},
   "source": [
    "# Stop Words removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6c36c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b1b91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    for words in words_tokens[i]:\n",
    "        if words  in stop_words:\n",
    "            words_tokens[i].remove(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5c7dad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'quick', 'brown', 'fox', 'jumps', 'the', 'lazy', 'cat'],\n",
       " ['I', 'like', 'eat', 'pizza', 'hamburgers'],\n",
       " ['The', 'sun', 'shining', 'the', 'birds', 'singing'],\n",
       " ['She', 'sells', 'seashells', 'the', 'seashore'],\n",
       " ['He', 'a', 'talented', 'musician', 'singer'],\n",
       " ['The', 'cat', 'the', 'hat', 'sat', 'a', 'mat'],\n",
       " ['It', \"'s\", 'raining', 'cats', 'dogs', 'outside'],\n",
       " ['The', 'United', 'States', 'America', 'a', 'large', 'country', '.'],\n",
       " ['I', 'need', 'buy', 'milk', ',', 'bread', ',', 'eggs', 'the', 'store', '.'],\n",
       " ['My', 'favorite', 'color', 'blue', ',', 'I', 'also', 'like', 'green', '.'],\n",
       " ['The', 'early', 'bird', 'catches', 'worm', '.'],\n",
       " ['The', 'world', 'full', 'wonder', 'mystery', '.'],\n",
       " ['I', 'a', 'dog', 'named', 'Max', 'a', 'cat', 'named', 'Whiskers', '.'],\n",
       " ['The', 'sky', 'a', 'beautiful', 'shade', 'blue', 'today', '.'],\n",
       " ['She', 'a', 'kind', 'caring', 'person', '.'],\n",
       " ['The', 'moon', 'full', 'tonight', 'the', 'stars', 'bright', '.'],\n",
       " ['I', 'love', 'read', 'books', 'watch', 'movies', '.'],\n",
       " ['The', 'grass', 'always', 'greener', 'the', 'side', '.'],\n",
       " ['The', 'ocean', 'vast', 'full', 'life', '.'],\n",
       " ['He', 'an', 'excellent', 'cook', 'loves', 'experiment', 'flavors', '.'],\n",
       " ['Life', 'a', 'journey', ',', 'a', 'destination', '.'],\n",
       " ['I', 'need', 'do', 'laundry', 'clean', 'house', 'today', '.'],\n",
       " ['The', 'mountains', 'majestic', 'awe-inspiring', '.'],\n",
       " ['She', 'a', 'passion', 'photography', 'takes', 'beautiful', 'pictures', '.'],\n",
       " ['The', 'apple', \"n't\", 'fall', 'far', 'the', 'tree', '.'],\n",
       " ['The', 'rainforest', 'a', 'complex', 'ecosystem', 'many', 'layers', '.'],\n",
       " ['He', 'a', 'hardworking', 'dedicated', 'employee', '.'],\n",
       " ['The', 'night', 'sky', 'a', 'canvas', 'stars', 'constellations', '.'],\n",
       " ['I', 'enjoy', 'hiking', 'being', 'outdoors', 'nature', '.'],\n",
       " ['The',\n",
       "  'city',\n",
       "  'never',\n",
       "  'sleeps',\n",
       "  'is',\n",
       "  'always',\n",
       "  'bustling',\n",
       "  'activity',\n",
       "  '.'],\n",
       " ['She', 'a', 'collection', 'antique', 'dolls', 'are', 'valuable', '.'],\n",
       " ['The',\n",
       "  'desert',\n",
       "  'a',\n",
       "  'harsh',\n",
       "  'environment',\n",
       "  'extreme',\n",
       "  'temperatures',\n",
       "  '.'],\n",
       " ['Life',\n",
       "  'too',\n",
       "  'short',\n",
       "  'waste',\n",
       "  'time',\n",
       "  'things',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'matter',\n",
       "  '.'],\n",
       " ['I', 'need', 'call', 'mother', 'wish', 'a', 'happy', 'birthday', '.'],\n",
       " ['The', 'universe', 'vast', 'infinite', '.'],\n",
       " ['She', 'a', 'talented', 'artist', 'creates', 'beautiful', 'paintings', '.'],\n",
       " ['The', 'river', 'flows', 'gently', 'the', 'countryside', '.'],\n",
       " ['He',\n",
       "  'a',\n",
       "  'skilled',\n",
       "  'carpenter',\n",
       "  'can',\n",
       "  'build',\n",
       "  'house',\n",
       "  'my',\n",
       "  'cat',\n",
       "  '.'],\n",
       " ['The', 'sun', 'sets', 'the', 'west', 'rises', 'the', 'east', '.'],\n",
       " ['My', 'cat', 'love', 'travel', 'explore', 'new', 'places', '.'],\n",
       " ['The', 'future', 'uncertain', ',', 'full', 'possibilities', '.'],\n",
       " ['She', 'a', 'brave', 'courageous', 'woman', '.'],\n",
       " ['The', 'forest', 'home', 'many', 'different', 'animals', 'plants', '.'],\n",
       " ['He', 'a', 'wise', 'knowledgeable', 'old', 'man', '.'],\n",
       " ['The', 'beach', 'a', 'great', 'place', 'relax', 'soak', 'the', 'sun', '.'],\n",
       " ['Life',\n",
       "  'like',\n",
       "  'box',\n",
       "  'chocolates',\n",
       "  ',',\n",
       "  'never',\n",
       "  'know',\n",
       "  'you',\n",
       "  \"'re\",\n",
       "  'going',\n",
       "  'get',\n",
       "  '.'],\n",
       " ['I', 'need', 'go', 'the', 'bank', 'deposit', 'paycheck', '.'],\n",
       " ['The', 'earth', 'a', 'fragile', 'ecosystem', 'must', 'protected', '.'],\n",
       " ['She', 'a', 'talented', 'musician', 'plays', 'piano', 'beautifully', '.'],\n",
       " ['The', 'wind', 'blows', 'gently', 'the', 'trees', '.'],\n",
       " ['He', 'successful', 'businessman', 'has', 'a', 'lot', 'experience', '.'],\n",
       " ['The', 'snow', 'falling', 'softly', 'outside', 'the', 'world', 'quiet', '.'],\n",
       " ['I', 'enjoy', 'cooking', 'experimenting', 'new', 'recipes', '.'],\n",
       " ['The', 'sky', 'a', 'beautiful', 'canvas', 'colors', 'a', 'sunset', '.'],\n",
       " ['The', 'world', 'changing', 'rapidly', 'we', 'must', 'adapt', '.'],\n",
       " ['She', 'a', 'kind-hearted', 'compassionate', 'person', '.'],\n",
       " ['The', 'jungle', 'full', 'danger', 'excitement', '.'],\n",
       " ['He', 'a', 'charismatic', 'persuasive', 'speaker', '.'],\n",
       " ['The', 'sea', 'vast', 'full', 'mystery', '.'],\n",
       " ['Life', 'full', 'surprises', 'unexpected', 'twists', '.'],\n",
       " ['I', 'love', 'pizza', '.'],\n",
       " ['My', 'favorite', 'color', 'blue', '.'],\n",
       " ['The', 'cat', 'jumped', 'the', 'table', '.'],\n",
       " ['I', 'like', 'run', 'the', 'park', '.'],\n",
       " ['The', 'dog', 'chased', 'ball', '.'],\n",
       " ['My', 'sister', 'studying', 'biology', '.'],\n",
       " ['I', 'enjoy', 'playing', 'video', 'games', '.'],\n",
       " ['The', 'sun', 'shining', 'brightly', 'today', '.'],\n",
       " ['My', 'parents', 'went', 'vacation', '.'],\n",
       " ['I', 'need', 'buy', 'groceries', '.'],\n",
       " ['I', 'learning', 'to', 'cook', '.'],\n",
       " ['My', 'brother', 'playing', 'basketball', '.'],\n",
       " ['I', 'a', 'headache', '.'],\n",
       " ['The', 'car', 'needs', 'oil', 'change', '.'],\n",
       " ['I', 'want', 'learn', 'to', 'play', 'guitar', '.'],\n",
       " ['The', 'sky', 'turning', 'red', 'sunset', '.'],\n",
       " ['My', 'friends', 'I', 'went', 'the', 'movies', '.'],\n",
       " ['I', 'allergic', 'peanuts', '.'],\n",
       " ['The', 'book', 'very', 'interesting', '.'],\n",
       " ['I', 'need', 'do', 'homework', '.'],\n",
       " ['The', 'train', 'delayed', '.'],\n",
       " ['I', 'went', 'a', 'walk', 'the', 'park', '.'],\n",
       " ['My', 'favorite', 'animal', 'cat', '.'],\n",
       " ['I', 'excited', 'the', 'concert', '.'],\n",
       " ['My', 'cat', 'black', 'color', '.'],\n",
       " ['I', 'watched', 'scary', 'movie', 'last', 'night', '.'],\n",
       " ['My', 'cat', 'love', 'swim', '.'],\n",
       " ['I', 'need', 'do', 'laundry', '.'],\n",
       " ['The', 'snow', 'falling', 'outside', '.'],\n",
       " ['I', 'love', 'going', 'the', 'beach', '.'],\n",
       " ['My', 'laptop', 'running', 'slow', '.'],\n",
       " ['I', 'want', 'another', 'cat', '.'],\n",
       " ['The', 'sun', 'setting', 'the', 'ocean', '.'],\n",
       " ['I', 'feeling', 'tired', 'today', '.'],\n",
       " ['The', 'internet', 'not', 'working'],\n",
       " ['I', 'want', 'learn', 'to', 'dance'],\n",
       " ['The', 'flowers', 'blooming', 'the', 'garden'],\n",
       " ['My', 'phone', 'battery', 'low'],\n",
       " ['I', 'need', 'go', 'grocery', 'shopping'],\n",
       " ['My', 'phone', 'turnoff']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1b4896",
   "metadata": {},
   "source": [
    "# Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b279efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "Term_Frequency_values=[]\n",
    "for words in words_tokens:\n",
    "    for X in words:\n",
    "        if X==\"cat\":\n",
    "            counter=counter+1\n",
    "            prob=1/len(words)\n",
    "            counter=0\n",
    "            Term_Frequency_values.append(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb27d48",
   "metadata": {},
   "source": [
    "# Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ede4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for words in words_tokens:\n",
    "    for x in words:\n",
    "        if x==\"cat\":\n",
    "            counter=counter+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84796425",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF_value=np.log(len(words_tokens)/counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20f0a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_score=[]\n",
    "for tf in Term_Frequency_values:\n",
    "    TF_IDF_score.append(tf*IDF_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0c6385",
   "metadata": {},
   "source": [
    "# 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c248e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.28782313662425574,\n",
       " 0.32894072757057796,\n",
       " 0.2302585092994046,\n",
       " 0.2302585092994046,\n",
       " 0.28782313662425574,\n",
       " 0.3837641821656743,\n",
       " 0.4605170185988092,\n",
       " 0.4605170185988092,\n",
       " 0.4605170185988092,\n",
       " 0.4605170185988092]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_IDF_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1331b5",
   "metadata": {},
   "source": [
    "# 3.3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfff484c",
   "metadata": {},
   "source": [
    "Following are the advantage and disadvantage of TF_IDF\n",
    "Advantages:\n",
    "1)Flexibility\n",
    "2)Intuitive interpretation:\n",
    "3)Scalability\n",
    "Limitations:\n",
    "1)Sensitivity to word order\n",
    "2)Difficulty in handling rare terms:\n",
    "3)Domain specific vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac442b6",
   "metadata": {},
   "source": [
    "# 3.4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5afec61f",
   "metadata": {},
   "source": [
    "Slightly different score in some of the files \n",
    "Compare 1.1 and 3.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34793dc",
   "metadata": {},
   "source": [
    "# Part : 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fee837",
   "metadata": {},
   "source": [
    "# 4.1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6c98219",
   "metadata": {},
   "source": [
    "In term of Flexibility and Scalability the TF_IDF is better \n",
    "In term of spelling correction,DNA sequencing and Machine translation Minimum edit distance is better "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1704af",
   "metadata": {},
   "source": [
    "# 4.2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db72ef51",
   "metadata": {},
   "source": [
    "To improve the accuracy of text similarity measures using TF-IDF and minimum edit distance, you can consider the following strategies:\n",
    "1)Pre_processing\n",
    "2)Parameters Tunning\n",
    "3)Hybrid approaches (Combine TF_IDF and Minimum edit distance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007315c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
